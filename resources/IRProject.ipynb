{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from natsort import natsorted\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_name = natsorted(os.listdir('file'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms after tokenization and stemming \n",
      "[['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser'], ['antoni', 'brutu', 'caeser', 'calpurnia'], ['merci', 'worser'], ['brutu', 'caeser', 'merci', 'worser'], ['caeser', 'merci', 'worser'], ['antoni', 'caeser', 'merci'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where'], ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(doc):\n",
    "    token_docs = word_tokenize(doc)\n",
    "    prepared_doc = []\n",
    "\n",
    "    for term in token_docs:\n",
    "        stemmed_term = stemmer.stem(term.lower())\n",
    "        prepared_doc.append(stemmed_term)\n",
    "\n",
    "    return prepared_doc\n",
    "\n",
    "\n",
    "document_of_terms = []\n",
    "for file in file_name:\n",
    "    with open(f'file/{file}', 'r') as f:\n",
    "        document = f.read()\n",
    "    document_of_terms.append(preprocessing(document))\n",
    "\n",
    "print('Terms after tokenization and stemming ')\n",
    "print(document_of_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional index\n",
      "{'antoni': [3, {0: [0], 1: [0], 5: [0]}], 'brutu': [3, {0: [1], 1: [1], 3: [0]}], 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}], 'cleopatra': [1, {0: [3]}], 'merci': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}], 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}], 'calpurnia': [1, {1: [3]}], 'angel': [3, {6: [0], 7: [0], 8: [0]}], 'fool': [4, {6: [1], 7: [1], 8: [1], 9: [0]}], 'fear': [3, {6: [2], 7: [2], 9: [1]}], 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}], 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}], 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}], 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}], 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]}\n"
     ]
    }
   ],
   "source": [
    "document_number = 0\n",
    "positional_index = {}\n",
    "\n",
    "for document in document_of_terms:\n",
    "    # For position and term in the tokens.\n",
    "    for positional, term in enumerate(document):\n",
    "        # If term already exists in the positional index dictionary.\n",
    "        if term in positional_index:\n",
    "            # Increment total freq by 1.\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "\n",
    "            # Check if the term has existed in that DocID before.\n",
    "            if document_number in positional_index[term][1]:\n",
    "                positional_index[term][1][document_number].append(positional)\n",
    "\n",
    "            else:\n",
    "                positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "        # If term does not exist in the positional index dictionary\n",
    "        # (first encounter).\n",
    "        else:\n",
    "            # Initialize the list.\n",
    "            positional_index[term] = []\n",
    "            # The total frequency is 1.\n",
    "            positional_index[term].append(1)\n",
    "            # The postings list is initially empty.\n",
    "            positional_index[term].append({})\n",
    "            # Add doc ID to postings list.\n",
    "            positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "    # Increment the file no. counter for document ID mapping\n",
    "    document_number += 1\n",
    "\n",
    "print('Positional index')\n",
    "print(positional_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++phrase query+++++\n",
      "['doc6']\n"
     ]
    }
   ],
   "source": [
    "query = input('Input Phrase Query: ')\n",
    "\n",
    "\n",
    "def query_input(q):\n",
    "    lis = [[] for _ in range(10)]\n",
    "    for term in preprocessing(query):\n",
    "        if term in positional_index:\n",
    "            for key in positional_index[term][1].keys():\n",
    "                if not lis[key] or lis[key][-1] == positional_index[term][1][key][0] - 1:\n",
    "                    lis[key].append(positional_index[term][1][key][0])\n",
    "\n",
    "    positions = [f'doc{pos}' for pos, lst in enumerate(lis, start=1) if len(lst) == len(preprocessing(query))]\n",
    "    return positions\n",
    "\n",
    "\n",
    "print('++++++phrase query+++++')\n",
    "print(query_input(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of boolean search: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "def boolean_search(query):\n",
    "    operators = [\"and\", \"or\", \"not\"]\n",
    "\n",
    "    def apply_operator(operand1, operator, operand2):\n",
    "        if operator == \"and\":\n",
    "            return list(set(positional_index[operand1][1].keys()) & set(positional_index[operand2][1].keys()))\n",
    "        elif operator == \"or\":\n",
    "            return list(set(positional_index[operand1][1].keys()) | set(positional_index[operand2][1].keys()))\n",
    "        elif operator == \"not\":\n",
    "            return list(set(positional_index[operand1][1].keys()) - set(positional_index[operand2][1].keys()))\n",
    "\n",
    "    def parse_query(subquery):\n",
    "        for operator in operators:\n",
    "            if operator in subquery:\n",
    "                operands = subquery.split(operator, 1)\n",
    "                operand1 = parse_query(operands[0].strip())\n",
    "                operand2 = parse_query(operands[1].strip())\n",
    "                return apply_operator(operand1, operator, operand2)\n",
    "        return subquery.strip()\n",
    "\n",
    "    result_query = parse_query(query)\n",
    "    return result_query\n",
    "\n",
    "def boolean_query_pre(query):\n",
    "    token_docs = word_tokenize(query)\n",
    "    prepared_doc = []\n",
    "\n",
    "    for term in token_docs:\n",
    "        stemmed_term = stemmer.stem(term.lower())\n",
    "        prepared_doc.append(stemmed_term)\n",
    "\n",
    "    return prepared_doc\n",
    "\n",
    "variable = input('Enter your boolean query: ')\n",
    "preprocessed_query_list = boolean_query_pre(variable)\n",
    "query_string = ' '.join(preprocessed_query_list)\n",
    "result = boolean_search(query_string)\n",
    "\n",
    "print(\"Result of boolean search:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print tables before Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni        1     1     0     0     0     1     0     0     0      0\n",
      "brutu         1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "merci         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angel         0     0     0     0     0     0     1     1     1      0\n",
      "fool          0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "Weighted TF\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutu       1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "merci       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angel       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fool        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "IDF\n",
      "          freq       idf\n",
      "antoni     3.0  0.522879\n",
      "brutu      3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "merci      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angel      3.0  0.522879\n",
      "fool       4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "TF.IDF\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antoni     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutu      0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "merci       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angel           0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fool            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antoni          0.0       0.0       0.0  \n",
      "brutu           0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "merci           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angel      0.522879  0.522879       0.0  \n",
      "fool        0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "Document Length\n",
      "   doc1_len  doc2_len  doc3_len  doc4_len  doc5_len  doc6_len  doc7_len  \\\n",
      "0  1.373462  1.279618  0.498974  0.782941  0.582747   0.67427  1.223496   \n",
      "\n",
      "   doc8_len  doc9_len  doc10_len  \n",
      "0  1.223496  1.106137   1.106137  \n",
      "Normalized TF.IDF\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "antoni     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
      "brutu      0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "merci      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
      "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
      "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "antoni     0.000000  0.000000  0.000000  0.000000  \n",
      "brutu      0.000000  0.000000  0.000000  0.000000  \n",
      "caeser     0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
      "merci      0.000000  0.000000  0.000000  0.000000  \n",
      "worser     0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
      "angel      0.427365  0.427365  0.472707  0.000000  \n",
      "fool       0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365  0.000000  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    "\n",
    "\n",
    "def get_term_freq(doc):\n",
    "    words_found = dict.fromkeys(all_words, 0)\n",
    "    for word in doc:\n",
    "        words_found[word] += 1\n",
    "    return words_found\n",
    "\n",
    "\n",
    "term_freq = pd.DataFrame(get_term_freq(document_of_terms[0]).values(), index=get_term_freq(document_of_terms[0]).keys())\n",
    "\n",
    "for i in range(1, len(document_of_terms)):\n",
    "    term_freq[i] = get_term_freq(document_of_terms[i]).values()\n",
    "\n",
    "term_freq.columns = ['doc' + str(i) for i in range(1, 11)]\n",
    "print('TF')\n",
    "print(term_freq)\n",
    "\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x > 0:\n",
    "        return math.log10(x) + 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "for i in range(1, len(document_of_terms) + 1):\n",
    "    term_freq['doc' + str(i)] = term_freq['doc' + str(i)].apply(get_weighted_term_freq)\n",
    "\n",
    "print('Weighted TF')\n",
    "print(term_freq)\n",
    "tfd = pd.DataFrame(columns=['freq', 'idf'])\n",
    "\n",
    "for i in range(len(term_freq)):\n",
    "\n",
    "    frequency = term_freq.iloc[i].values.sum()\n",
    "\n",
    "    tfd.loc[i, 'freq'] = frequency\n",
    "\n",
    "    tfd.loc[i, 'idf'] = math.log10(10 / (float(frequency)))\n",
    "\n",
    "tfd.index = term_freq.index\n",
    "\n",
    "print('IDF')\n",
    "print(tfd)\n",
    "\n",
    "term_freq_inve_doc_freq = term_freq.multiply(tfd['idf'], axis=0)\n",
    "\n",
    "print('TF.IDF')\n",
    "print(term_freq_inve_doc_freq)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "document_length = pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_docs_length(col):\n",
    "    return np.sqrt(term_freq_inve_doc_freq[col].apply(lambda x: x ** 2).sum())\n",
    "\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    document_length.loc[0, column + '_len'] = get_docs_length(column)\n",
    "\n",
    "print('Document Length')\n",
    "print(document_length)\n",
    "\n",
    "normalized_term_freq_idf = pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_normalized(col, x):\n",
    "    try:\n",
    "        return x / document_length[col + '_len'].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    normalized_term_freq_idf[column] = term_freq_inve_doc_freq[column].apply(lambda x: get_normalized(column, x))\n",
    "\n",
    "print('Normalized TF.IDF')\n",
    "print(normalized_term_freq_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_term_frequencies_from_files(folder_path):\n",
    "    terms = set()\n",
    "    term_freq_data = {}\n",
    "\n",
    "    # Assuming files are named 1.txt, 2.txt, ..., 10.txt\n",
    "    for i in range(1, 10):\n",
    "        file_name = f'{i}.txt'\n",
    "        file_path = os.path.join(file, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            text = read_text_file(file_path)\n",
    "            file_terms = preprocess_text(text)\n",
    "            terms.update(file_terms)\n",
    "            term_freq_data[file_name] = file_terms\n",
    "\n",
    "    term_freq_df = pd.DataFrame(term_freq_data)\n",
    "    term_freq_df = term_freq_df.apply(lambda x: x.map(lambda y: file_terms.count(y)))\n",
    "\n",
    "    return term_freq_df, terms\n",
    "\n",
    "def display_term_frequencies(term_freq_df):\n",
    "    # Transpose the DataFrame for better display\n",
    "    transposed_df = term_freq_df.transpose()\n",
    "\n",
    "    print(\"Term Frequencies:\")\n",
    "    print(transposed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Details\n",
      "        tf  w_tf       idf    tf_idf  normalized\n",
      "antoni   1   1.0  0.522879  0.522879    0.707107\n",
      "brutu    1   1.0  0.522879  0.522879    0.707107\n",
      "AND Operation Result:\n",
      "['doc1']\n",
      "OR Operation Result:\n",
      "['doc0', 'doc1', 'doc3', 'doc5']\n",
      "\n",
      "Product (query * matched doc) for AND Operation:\n",
      "            doc1      doc2\n",
      "antoni  0.269196  0.288939\n",
      "brutu   0.269196  0.288939\n",
      "\n",
      "Product Sum for AND Operation:\n",
      "doc1    0.538393\n",
      "doc2    0.577877\n",
      "dtype: float64\n",
      "\n",
      "Product (query * matched doc) for OR Operation:\n",
      "            doc1      doc2  doc3      doc4  doc5      doc6  doc7  doc8  doc9  \\\n",
      "antoni  0.269196  0.288939   0.0  0.000000   0.0  0.548343   0.0   0.0   0.0   \n",
      "brutu   0.269196  0.288939   0.0  0.472234   0.0  0.000000   0.0   0.0   0.0   \n",
      "\n",
      "        doc10  \n",
      "antoni    0.0  \n",
      "brutu     0.0  \n",
      "\n",
      "Product Sum for OR Operation:\n",
      "doc1     0.538393\n",
      "doc2     0.577877\n",
      "doc3     0.000000\n",
      "doc4     0.472234\n",
      "doc5     0.000000\n",
      "doc6     0.548343\n",
      "doc7     0.000000\n",
      "doc8     0.000000\n",
      "doc9     0.000000\n",
      "doc10    0.000000\n",
      "dtype: float64\n",
      "\n",
      "Query Length\n",
      "0.7394622130520805\n",
      "\n",
      "Cosine Similarity for AND Operation:\n",
      "doc1    0.538393\n",
      "doc2    0.577877\n",
      "dtype: float64\n",
      "\n",
      "Cosine Similarity for OR Operation:\n",
      "doc1     0.538393\n",
      "doc2     0.577877\n",
      "doc3     0.000000\n",
      "doc4     0.472234\n",
      "doc5     0.000000\n",
      "doc6     0.548343\n",
      "doc7     0.000000\n",
      "doc8     0.000000\n",
      "doc9     0.000000\n",
      "doc10    0.000000\n",
      "dtype: float64\n",
      "Returned docs for AND Operation:\n",
      "doc2\n",
      "doc1\n",
      "Returned docs for OR Operation:\n",
      "doc2\n",
      "doc6\n",
      "doc1\n",
      "doc4\n",
      "doc3\n",
      "doc5\n",
      "doc7\n",
      "doc8\n",
      "doc9\n",
      "doc10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Google\\AppData\\Local\\Temp\\ipykernel_15068\\2204103772.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values ** 2))\n",
      "C:\\Users\\Google\\AppData\\Local\\Temp\\ipykernel_15068\\2204103772.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.7071067811865475' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values ** 2))\n"
     ]
    }
   ],
   "source": [
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x) + 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def insert_query(q):\n",
    "    query_terms = preprocessing(q)\n",
    "    query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "    query['tf'] = [1 if x in query_terms else 0 for x in list(normalized_term_freq_idf.index)]\n",
    "    query['w_tf'] = query['tf'].apply(lambda x: get_w_tf(x))\n",
    "    product = normalized_term_freq_idf.multiply(query['w_tf'], axis=0)\n",
    "    query['idf'] = tfd['idf'] * query['w_tf']\n",
    "    query['tf_idf'] = query['w_tf'] * query['idf']\n",
    "    query['normalized'] = 0\n",
    "\n",
    "    for i in range(len(query)):\n",
    "        query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values ** 2))\n",
    "\n",
    "    print('Query Details')\n",
    "    print(query.loc[query_terms])\n",
    "\n",
    "    # Boolean operators\n",
    "    and_docs = set(range(1, 11))  # Assume AND operation returns all documents initially\n",
    "    or_docs = set()  # Assume OR operation returns an empty set initially\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term in positional_index:\n",
    "            and_docs &= set(positional_index[term][1].keys())\n",
    "            or_docs |= set(positional_index[term][1].keys())\n",
    "\n",
    "    and_docs = [f'doc{doc}' for doc in and_docs]\n",
    "    or_docs = [f'doc{doc}' for doc in or_docs]\n",
    "\n",
    "    print('AND Operation Result:')\n",
    "    print(and_docs)\n",
    "\n",
    "    print('OR Operation Result:')\n",
    "    print(or_docs)\n",
    "\n",
    "    product = normalized_term_freq_idf.multiply(query['normalized'], axis=0)\n",
    "\n",
    "    scores_and = {}\n",
    "    scores_or = {}\n",
    "\n",
    "    for col in product.columns:\n",
    "        if 0 in product[col].loc[query_terms].values:\n",
    "            pass\n",
    "        else:\n",
    "            scores_and[col] = product[col].sum()\n",
    "\n",
    "    for col in product.columns:\n",
    "        scores_or[col] = product[col].sum()\n",
    "\n",
    "    product_result_and = product[list(scores_and.keys())].loc[query_terms]\n",
    "    product_result_or = product[list(scores_or.keys())].loc[query_terms]\n",
    "\n",
    "    print()\n",
    "    print('Product (query * matched doc) for AND Operation:')\n",
    "    print(product_result_and)\n",
    "    print()\n",
    "    print('Product Sum for AND Operation:')\n",
    "    print(product_result_and.sum())\n",
    "\n",
    "    print()\n",
    "    print('Product (query * matched doc) for OR Operation:')\n",
    "    print(product_result_or)\n",
    "    print()\n",
    "    print('Product Sum for OR Operation:')\n",
    "    print(product_result_or.sum())\n",
    "\n",
    "    print()\n",
    "    print('Query Length')\n",
    "    q_len = math.sqrt(sum([x ** 2 for x in query['idf'].loc[query_terms]]))\n",
    "    print(q_len)\n",
    "\n",
    "    print()\n",
    "    print('Cosine Similarity for AND Operation:')\n",
    "    print(product_result_and.sum())\n",
    "\n",
    "    print()\n",
    "    print('Cosine Similarity for OR Operation:')\n",
    "    print(product_result_or.sum())\n",
    "\n",
    "    sorted_scores_and = sorted(scores_and.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_scores_or = sorted(scores_or.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print('Returned docs for AND Operation:')\n",
    "    for tuple in sorted_scores_and:\n",
    "        print(tuple[0])\n",
    "\n",
    "    print('Returned docs for OR Operation:')\n",
    "    for tuple in sorted_scores_or:\n",
    "        print(tuple[0])\n",
    "\n",
    "\n",
    "q = input('Input Query for print Query details and matched document: ')\n",
    "insert_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'put_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m typle \u001b[38;5;129;01min\u001b[39;00m sorted_scores:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(typle[\u001b[38;5;241m0\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[43minsert_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mantony brutus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36minsert_query\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_query\u001b[39m(q):\n\u001b[1;32m----> 2\u001b[0m     docs_found \u001b[38;5;241m=\u001b[39m \u001b[43mput_query\u001b[49m(q, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m docs_found \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Fount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'put_query' is not defined"
     ]
    }
   ],
   "source": [
    "def insert_query(q):\n",
    "    docs_found = put_query(q, 2)\n",
    "    if docs_found == []:\n",
    "        return \"Not Fount\"\n",
    "    new_q = preprocessing(q)\n",
    "    query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "    query['tf'] = [1 if x in new_q else 0 for x in list(normalized_term_freq_idf.index)]\n",
    "    query['w_tf'] = query['tf'].apply(lambda x : get_w_tf(x))\n",
    "    product = normalized_term_freq_idf.multiply(query['w_tf'], axis=0)\n",
    "    query['idf'] = tdf['idf'] * query['w_tf']\n",
    "    query['tf_idf'] = query['w_tf'] * query['idf']\n",
    "    query['normalized'] = 0\n",
    "    for i in range(len(query)):\n",
    "        query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n",
    "    print('Query Details')\n",
    "    print(query.loc[new_q])\n",
    "    product2 = product.multiply(query['normalized'], axis=0)\n",
    "    scores = {}\n",
    "    for col in put_query(q, 2):\n",
    "            scores[col] = product2[col].sum()\n",
    "    product_result = product2[list(scores.keys())].loc[new_q]\n",
    "    print()\n",
    "    print('Product (query*matched doc)')\n",
    "    print(product_result)\n",
    "    print()\n",
    "    print('product sum')\n",
    "    print(product_result.sum())\n",
    "    print()\n",
    "    print('Query Length')\n",
    "    q_len = math.sqrt(sum([x**2 for x in query['idf'].loc[new_q]]))\n",
    "    print(q_len)\n",
    "    print()\n",
    "    print('Cosine Simliarity')\n",
    "    print(product_result.sum())\n",
    "    print()\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    print('Returned docs')\n",
    "    for typle in sorted_scores:\n",
    "        print(typle[0], end=\" \")\n",
    "        \n",
    "\n",
    "insert_query('antony brutus')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
