{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from natsort import natsorted\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_name = natsorted(os.listdir('file'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms after tokenization and stemming \n",
      "[['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser'], ['antoni', 'brutu', 'caeser', 'calpurnia'], ['merci', 'worser'], ['brutu', 'caeser', 'merci', 'worser'], ['caeser', 'merci', 'worser'], ['antoni', 'caeser', 'merci'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where'], ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(doc):\n",
    "    token_docs = word_tokenize(doc)\n",
    "    prepared_doc = []\n",
    "\n",
    "    for term in token_docs:\n",
    "        stemmed_term = stemmer.stem(term.lower())\n",
    "        prepared_doc.append(stemmed_term)\n",
    "\n",
    "    return prepared_doc\n",
    "\n",
    "\n",
    "document_of_terms = []\n",
    "for file in file_name:\n",
    "    with open(f'file/{file}', 'r') as f:\n",
    "        document = f.read()\n",
    "    document_of_terms.append(preprocessing(document))\n",
    "\n",
    "print('Terms after tokenization and stemming ')\n",
    "print(document_of_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional index\n",
      "{'antoni': [3, {0: [0], 1: [0], 5: [0]}], 'brutu': [3, {0: [1], 1: [1], 3: [0]}], 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}], 'cleopatra': [1, {0: [3]}], 'merci': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}], 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}], 'calpurnia': [1, {1: [3]}], 'angel': [3, {6: [0], 7: [0], 8: [0]}], 'fool': [4, {6: [1], 7: [1], 8: [1], 9: [0]}], 'fear': [3, {6: [2], 7: [2], 9: [1]}], 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}], 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}], 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}], 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}], 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]}\n"
     ]
    }
   ],
   "source": [
    "document_number = 0\n",
    "positional_index = {}\n",
    "\n",
    "for document in document_of_terms:\n",
    "    # For position and term in the tokens.\n",
    "    for positional, term in enumerate(document):\n",
    "        # If term already exists in the positional index dictionary.\n",
    "        if term in positional_index:\n",
    "            # Increment total freq by 1.\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "\n",
    "            # Check if the term has existed in that DocID before.\n",
    "            if document_number in positional_index[term][1]:\n",
    "                positional_index[term][1][document_number].append(positional)\n",
    "\n",
    "            else:\n",
    "                positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "        # If term does not exist in the positional index dictionary\n",
    "        # (first encounter).\n",
    "        else:\n",
    "            # Initialize the list.\n",
    "            positional_index[term] = []\n",
    "            # The total frequency is 1.\n",
    "            positional_index[term].append(1)\n",
    "            # The postings list is initially empty.\n",
    "            positional_index[term].append({})\n",
    "            # Add doc ID to postings list.\n",
    "            positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "    # Increment the file no. counter for document ID mapping\n",
    "    document_number += 1\n",
    "\n",
    "print('Positional index')\n",
    "print(positional_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++phrase query+++++\n",
      "['doc1', 'doc3', 'doc4', 'doc5']\n"
     ]
    }
   ],
   "source": [
    "query = input('Input Phrase Query: ')\n",
    "\n",
    "\n",
    "def query_input(q):\n",
    "    lis = [[] for _ in range(10)]\n",
    "    for term in preprocessing(query):\n",
    "        if term in positional_index:\n",
    "            for key in positional_index[term][1].keys():\n",
    "                if not lis[key] or lis[key][-1] == positional_index[term][1][key][0] - 1:\n",
    "                    lis[key].append(positional_index[term][1][key][0])\n",
    "\n",
    "    positions = [f'doc{pos}' for pos, lst in enumerate(lis, start=1) if len(lst) == len(preprocessing(query))]\n",
    "    return positions\n",
    "\n",
    "\n",
    "print('++++++phrase query+++++')\n",
    "print(query_input(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print tables before Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni        1     1     0     0     0     1     0     0     0      0\n",
      "brutu         1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "merci         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angel         0     0     0     0     0     0     1     1     1      0\n",
      "fool          0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "Weighted TF\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antoni      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutu       1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "merci       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angel       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fool        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "IDF\n",
      "          freq       idf\n",
      "antoni     3.0  0.522879\n",
      "brutu      3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "merci      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angel      3.0  0.522879\n",
      "fool       4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "TF.IDF\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antoni     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutu      0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "merci       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angel           0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fool            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antoni          0.0       0.0       0.0  \n",
      "brutu           0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "merci           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angel      0.522879  0.522879       0.0  \n",
      "fool        0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "Document Length\n",
      "   doc1_len  doc2_len  doc3_len  doc4_len  doc5_len  doc6_len  doc7_len  \\\n",
      "0  1.373462  1.279618  0.498974  0.782941  0.582747   0.67427  1.223496   \n",
      "\n",
      "   doc8_len  doc9_len  doc10_len  \n",
      "0  1.223496  1.106137   1.106137  \n",
      "Normalized TF.IDF\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "antoni     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
      "brutu      0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "merci      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
      "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
      "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "antoni     0.000000  0.000000  0.000000  0.000000  \n",
      "brutu      0.000000  0.000000  0.000000  0.000000  \n",
      "caeser     0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
      "merci      0.000000  0.000000  0.000000  0.000000  \n",
      "worser     0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
      "angel      0.427365  0.427365  0.472707  0.000000  \n",
      "fool       0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365  0.000000  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    "\n",
    "\n",
    "def get_term_freq(doc):\n",
    "    words_found = dict.fromkeys(all_words, 0)\n",
    "    for word in doc:\n",
    "        words_found[word] += 1\n",
    "    return words_found\n",
    "\n",
    "\n",
    "term_freq = pd.DataFrame(get_term_freq(document_of_terms[0]).values(), index=get_term_freq(document_of_terms[0]).keys())\n",
    "\n",
    "for i in range(1, len(document_of_terms)):\n",
    "    term_freq[i] = get_term_freq(document_of_terms[i]).values()\n",
    "\n",
    "term_freq.columns = ['doc' + str(i) for i in range(1, 11)]\n",
    "print('TF')\n",
    "print(term_freq)\n",
    "\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x > 0:\n",
    "        return math.log10(x) + 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "for i in range(1, len(document_of_terms) + 1):\n",
    "    term_freq['doc' + str(i)] = term_freq['doc' + str(i)].apply(get_weighted_term_freq)\n",
    "\n",
    "print('Weighted TF')\n",
    "print(term_freq)\n",
    "tfd = pd.DataFrame(columns=['freq', 'idf'])\n",
    "\n",
    "for i in range(len(term_freq)):\n",
    "\n",
    "    frequency = term_freq.iloc[i].values.sum()\n",
    "\n",
    "    tfd.loc[i, 'freq'] = frequency\n",
    "\n",
    "    tfd.loc[i, 'idf'] = math.log10(10 / (float(frequency)))\n",
    "\n",
    "tfd.index = term_freq.index\n",
    "\n",
    "print('IDF')\n",
    "print(tfd)\n",
    "\n",
    "term_freq_inve_doc_freq = term_freq.multiply(tfd['idf'], axis=0)\n",
    "\n",
    "print('TF.IDF')\n",
    "print(term_freq_inve_doc_freq)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "document_length = pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_docs_length(col):\n",
    "    return np.sqrt(term_freq_inve_doc_freq[col].apply(lambda x: x ** 2).sum())\n",
    "\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    document_length.loc[0, column + '_len'] = get_docs_length(column)\n",
    "\n",
    "print('Document Length')\n",
    "print(document_length)\n",
    "\n",
    "normalized_term_freq_idf = pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_normalized(col, x):\n",
    "    try:\n",
    "        return x / document_length[col + '_len'].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    normalized_term_freq_idf[column] = term_freq_inve_doc_freq[column].apply(lambda x: get_normalized(column, x))\n",
    "\n",
    "print('Normalized TF.IDF')\n",
    "print(normalized_term_freq_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput Query for print Query details and matched document: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     84\u001b[0m boolean_operator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput Boolean Operator (AND or OR): \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[43minsert_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboolean_operator\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36minsert_query\u001b[1;34m(q, boolean_operator)\u001b[0m\n\u001b[0;32m     19\u001b[0m query_terms \u001b[38;5;241m=\u001b[39m preprocessing(q)\n\u001b[0;32m     20\u001b[0m query \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39mnormalized_term_freq_idf\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m---> 21\u001b[0m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery_terms\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(normalized_term_freq_idf\u001b[38;5;241m.\u001b[39mindex)]\n\u001b[0;32m     22\u001b[0m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_tf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_w_tf(x))\n\u001b[0;32m     23\u001b[0m product \u001b[38;5;241m=\u001b[39m normalized_term_freq_idf\u001b[38;5;241m.\u001b[39mmultiply(query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_tf\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x) + 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x) + 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def preprocessing(q):\n",
    "    # Add your preprocessing logic here\n",
    "    pass\n",
    "\n",
    "def insert_query(q, boolean_operator):\n",
    "    query_terms = preprocessing(q)\n",
    "    query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "    query['tf'] = [1 if x in query_terms else 0 for x in list(normalized_term_freq_idf.index)]\n",
    "    query['w_tf'] = query['tf'].apply(lambda x: get_w_tf(x))\n",
    "    product = normalized_term_freq_idf.multiply(query['w_tf'], axis=0)\n",
    "    query['idf'] = tfd['idf'] * query['w_tf']\n",
    "    query['tf_idf'] = query['w_tf'] * query['idf']\n",
    "    query['normalized'] = 0\n",
    "\n",
    "    for i in range(len(query)):\n",
    "        query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values ** 2))\n",
    "\n",
    "    print('Query Details')\n",
    "    print(query.loc[query_terms])\n",
    "\n",
    "    # Boolean operators\n",
    "    and_docs = set(range(1, 11))  # Assume AND operation returns all documents initially\n",
    "    or_docs = set()  # Assume OR operation returns an empty set initially\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term in positional_index:\n",
    "            and_docs &= set(positional_index[term][1].keys())\n",
    "            or_docs |= set(positional_index[term][1].keys())\n",
    "\n",
    "    and_docs = [f'doc{doc}' for doc in and_docs]\n",
    "    or_docs = [f'doc{doc}' for doc in or_docs]\n",
    "\n",
    "    print(f'{boolean_operator} Operation Result:')\n",
    "    print(and_docs if boolean_operator == 'AND' else or_docs)\n",
    "\n",
    "    product = normalized_term_freq_idf.multiply(query['normalized'], axis=0)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for col in product.columns:\n",
    "        if 0 in product[col].loc[query_terms].values:\n",
    "            pass\n",
    "        else:\n",
    "            scores[col] = product[col].sum()\n",
    "\n",
    "    product_result = product[list(scores.keys())].loc[query_terms]\n",
    "\n",
    "    print()\n",
    "    print(f'Product (query * matched doc) for {boolean_operator} Operation:')\n",
    "    print(product_result)\n",
    "    print()\n",
    "    print(f'Product Sum for {boolean_operator} Operation:')\n",
    "    print(product_result.sum())\n",
    "\n",
    "    print()\n",
    "    print('Query Length')\n",
    "    q_len = math.sqrt(sum([x ** 2 for x in query['idf'].loc[query_terms]]))\n",
    "    print(q_len)\n",
    "\n",
    "    print()\n",
    "    print(f'Cosine Similarity for {boolean_operator} Operation:')\n",
    "    print(product_result.sum())\n",
    "\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f'Returned docs for {boolean_operator} Operation:')\n",
    "    for tuple in sorted_scores:\n",
    "        print(tuple[0])\n",
    "\n",
    "q = input('Input Query for print Query details and matched document: ')\n",
    "boolean_operator = input('Input Boolean Operator (AND or OR): ')\n",
    "insert_query(q, boolean_operator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
